À fin de pouvoir affronter notre analyse, nous devons reduire le corpus de façon
telle qu'on puisse explorer les données de manière rapide et interactive.
Notre corpus de base consiste en touts les articles de la `Gazette de Lausanne' et
du `Journal de Genève' de 1900 jusque à 1999. Le corpus nous parviens compressé
en format bzip2 \cite{bzip} et occupe en total 18 Go d'éspace sur dique. Quand
les données sont décompressées, le volume des donnés augmente de 10 fois. Ceci
nous cause un problème, car ~200 Go de données ne rentre pas dans la memoir RAM
d'un ordinateur, et cela limite les méthodes de questionnement des données que
nous pouvons appliquer.
Pour resoudre ce problème, nous pourions opérer sur les données compressées, en
les décompressant au moment du besoin. Cette approche est raisonable, mais
introduit des longs temps d'élaboration. Effectivement, le format bzip2 permets
une forte réduction de la taille des fichier, mais au coût d'un long temps de
décompression. Un experiment nous confirme que pour chercher les môts `secret
bancaire' dans un fichier bzip2 contennant les articles du `Journal de Genève'
de 1970, sur un temps d'élaboration total de 24.7 secondes, la décompression
bzip2 nécessite 24.1s et la recherche de môts seulement 0.6s. Nous pouvons donc
épargner beaucoup de temps en travaillant sur les données décompressés à l'avance.
Nous souhaitons ne pas limiter notre corpus aux articles qui contiennent un des
môts clés, parceque les autres articles nous seront utiles pour effectuer des
analyses comme trouver les autres articles écrits par un certain auteur et voir
si l'auteur est plutot un généraliste, ou un spécialiste.
Le problème suivant est de réduire les 200 Go de données brutes pour les stoquer
et manipuler aisement. Pour cela, nous décidons d'ignorer les méta-données sur
la position des môts dans les article. Ces méta-données occupent environ 90%
du volume des données et ne sont pas necessaires à nos analyses. Nous les gardons
seulement pour les (peux) articles qui contiennent un de nos môts clés. 
De cette façon, nous travaillons avec au total un peu plus 9 Go de données
décompressées. Une recherche par môts clés passe ainsi de 1h30 sur les données
compressées a 1 minute sur les données nétoyées et décompressées.
